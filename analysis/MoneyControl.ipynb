{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from deco import *\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def retry(ExceptionToCheck, tries=4, delay=3, backoff=2, logger=None):\n",
    "    \"\"\"Retry calling the decorated function using an exponential backoff.\n",
    "\n",
    "    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n",
    "    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "\n",
    "    :param ExceptionToCheck: the exception to check. may be a tuple of\n",
    "        exceptions to check\n",
    "    :type ExceptionToCheck: Exception or tuple\n",
    "    :param tries: number of times to try (not retry) before giving up\n",
    "    :type tries: int\n",
    "    :param delay: initial delay between retries in seconds\n",
    "    :type delay: int\n",
    "    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n",
    "        each retry\n",
    "    :type backoff: int\n",
    "    :param logger: logger to use. If None, print\n",
    "    :type logger: logging.Logger instance\n",
    "    \"\"\"\n",
    "    def deco_retry(f):\n",
    "\n",
    "        @wraps(f)\n",
    "        def f_retry(*args, **kwargs):\n",
    "            mtries, mdelay = tries, delay\n",
    "            while mtries > 1:\n",
    "                try:\n",
    "                    return f(*args, **kwargs)\n",
    "                except ExceptionToCheck as e:\n",
    "                    msg = \"%s, Retrying in %d seconds...\" % (str(e), mdelay)\n",
    "                    if logger:\n",
    "                        logger.warning(msg)\n",
    "                    else:\n",
    "                        print(msg)\n",
    "                    time.sleep(mdelay)\n",
    "                    mtries -= 1\n",
    "                    mdelay *= backoff\n",
    "            return f(*args, **kwargs)\n",
    "\n",
    "        return f_retry  # true decorator\n",
    "\n",
    "    return deco_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist(data, fileName, path):\n",
    "    json_string = json.dumps(data)\n",
    "    print(\"Writing to file \" + path + fileName)\n",
    "    with open(path + fileName, \"w\") as file:\n",
    "        file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistDF(df, symbol, path):\n",
    "    print(\"Persisting \" + symbol)\n",
    "    if(os.path.exists(path + 'NSE:' + symbol + \".csv\")):\n",
    "        print(\"%s already persisted\" % symbol)\n",
    "    else:\n",
    "        df.to_csv(path + 'NSE:' + symbol + \".csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fileName, path):\n",
    "    data = {}\n",
    "    with open(path + fileName) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAndStrip(text, delimiter):\n",
    "    return map(lambda s: s.strip(), text.split(delimiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMCIndexList():\n",
    "    index_url_prefix = \"https://www.moneycontrol.com/india/stockpricequote/\"\n",
    "    letters = map(chr, range(65, 91))\n",
    "    letters.append(\"others\")\n",
    "    IndexList = []\n",
    "    for letter in letters:\n",
    "        page_url = index_url_prefix + letter\n",
    "        page = requests.get(page_url)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "        table = soup.find('table', class_='pcq_tbl MT10')\n",
    "        links = table.find_all('a')\n",
    "        for link in links:\n",
    "            IndexList.append({'title':link['title'], 'link':link['href']})\n",
    "    return IndexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetaData(soup) :\n",
    "    div = soup.find('div', class_='FL gry10')\n",
    "    return {ele[0]: ele[1] for ele in map(lambda ele: splitAndStrip(ele, ':') ,filter(None, splitAndStrip(div.text, '|')))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(soup):\n",
    "    slider = soup.find(id='slider')\n",
    "    children = slider.children\n",
    "    interested = [\"CORPORATE ACTION\", \"FINANCIALS\", \"ANNUAL REPORT\", \"SHAREHOLDING\"]\n",
    "    info = {}\n",
    "    for child in children:\n",
    "        if((isinstance(child, Tag)) and (child.name == 'dt') and (child.text in interested)):\n",
    "            key = child.text\n",
    "            value = {}\n",
    "            while True:\n",
    "                next_child = next(children)\n",
    "                if (isinstance(next_child, Tag)):\n",
    "                    lis = next_child.find_all('a')\n",
    "                    value.update({li.text : 'https://www.moneycontrol.com' + li['href'] for li in lis})\n",
    "                    break\n",
    "            info.update({key : value})\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanIndex(index):\n",
    "    title = index['title']\n",
    "    link = index['link']\n",
    "    return {'title': title, 'link': link}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateIndex(index):\n",
    "    index = cleanIndex(index)\n",
    "    page_url = index['link']\n",
    "    page = requests.get(page_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    metadata = getMetaData(soup)\n",
    "    info = getInfo(soup)\n",
    "    index['info'] = info\n",
    "    index['metadata'] = metadata\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistIndex(index):\n",
    "    title = index['title']\n",
    "    fileName = title.replace(\" \", \"\")\n",
    "    path = 'data/MC/'\n",
    "    persist(index, fileName, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFileMap():\n",
    "    fileMap = {}\n",
    "    files = os.listdir('data/MC')\n",
    "    files.sort()\n",
    "    for f in files:\n",
    "        data = load(f, 'data/MC/')\n",
    "        if('metadata' in data):\n",
    "            if(('NSE' in data['metadata']) and (len(data['metadata']['NSE']) is not 0)):\n",
    "                fileMap.update({data['metadata']['NSE'] : f})\n",
    "            elif(('BSE' in data['metadata']) and (len(data['metadata']['BSE']) is not 0)):\n",
    "                fileMap.update({data['metadata']['BSE'] : f})\n",
    "    path = 'data/MC/'\n",
    "    fileName = 'fileMap'\n",
    "    persist(fileMap, fileName, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileMap():\n",
    "    path = 'data/MC/'\n",
    "    fileName = 'fileMap'\n",
    "    return load(fileName, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCA(page_url):\n",
    "    page = requests.get(page_url)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    table = soup.find('table', class_='tbldivid')\n",
    "    columns = map(lambda col: col.text, table.find_all('th'))\n",
    "    data_list = map(lambda ele: ele.text if((not 'information available for' in ele.text) and (len(ele.text) != 0)) else None, table.find_all('td'))\n",
    "    data_list = filter(lambda x: x is not None, data_list)\n",
    "    rows = map(lambda lst: dict(zip(columns, lst)) , [data_list[i:i+len(columns)] for i in range(0, len(data_list), len(columns))])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAndPersistCA(symbol):\n",
    "    if(os.path.exists('data/CA/' + symbol) == False):\n",
    "        interested = ['Splits', 'Bonus']\n",
    "        symbol = symbol.upper()\n",
    "        fileMap = getFileMap()\n",
    "        fileName = fileMap[symbol]\n",
    "        metaData = load(fileName, 'data/MC/')\n",
    "        ca = metaData['info']['CORPORATE ACTION']\n",
    "        data = map(lambda i: {i : parseCA(ca[i])}, interested)\n",
    "        persist(data, symbol, 'data/CA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@concurrent\n",
    "@retry(Exception, tries=3)\n",
    "def updateAndPersistIndex(index):\n",
    "    title = index['title']\n",
    "    fileName = title.replace(\" \", \"\")\n",
    "    if(not os.path.exists('data/MC/' + fileName)):\n",
    "        print(\"Processing : \" + title)\n",
    "        index = updateIndex(index)\n",
    "        persistIndex(index)\n",
    "    else:\n",
    "        print(\"Already Processed \" + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@synchronized\n",
    "def run():\n",
    "    mcIndexList = buildMCIndexList()\n",
    "    print(\"To Process\" + str(len(mcIndexList)))\n",
    "    for index in mcIndexList:\n",
    "        updateAndPersistIndex(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSplitFactor(splits):\n",
    "    factor = []\n",
    "    for split in splits:\n",
    "        rate = float(split['Old FV'])/ float(split['New FV'])\n",
    "        date = split['Ex-Split Date'] if split['Ex-Split Date'] != '-' else split['Announcement Date']\n",
    "        factor.append({'date': date, 'factor': rate})\n",
    "    if(len(factor) != 0):\n",
    "        df = pd.DataFrame(factor)\n",
    "        df.date = pd.to_datetime(df.date, format = '%d-%m-%Y')\n",
    "        df = df.set_index('date')\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBonusFactor(bonuses):\n",
    "    factor = []\n",
    "    for bonus in bonuses:\n",
    "        ratio = bonus['Bonus Ratio'].split(':')\n",
    "        rate = (float(ratio[0]) + float(ratio[1])) / float(ratio[1])\n",
    "        date = bonus['Ex-Bonus Date'] if bonus['Ex-Bonus Date'] != '-' else bonus['Announcement Date']\n",
    "        factor.append({'date': date, 'factor': rate})\n",
    "    if(len(factor) != 0):\n",
    "        df = pd.DataFrame(factor)\n",
    "        df.date = pd.to_datetime(df.date, format = '%d-%m-%Y')\n",
    "        df = df.set_index('date')\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "    else: \n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coporateFactor(ca):\n",
    "    bonus_factor = computeBonusFactor(ca[1][u'Bonus'])\n",
    "    split_factor = computeSplitFactor(ca[0][u'Splits'])\n",
    "    return bonus_factor.multiply(split_factor, fill_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustmentFactor(symbol):\n",
    "    ca = load(symbol, 'data/CA/')\n",
    "    bNsFactor = coporateFactor(ca)\n",
    "    bNsFactor = bNsFactor.sort_index(ascending=False).cumprod().sort_index()\n",
    "    default_factor = pd.DataFrame(pd.date_range('1990-01-01', pd.Timestamp.today()), columns=['date'])\n",
    "    default_factor['factor'] = 1\n",
    "    default_factor = default_factor.set_index(['date'])\n",
    "    adjFactor = default_factor.multiply(bNsFactor, fill_value=1)\n",
    "    adjFactor[adjFactor['factor'] == 1] = np.nan\n",
    "    adjFactor = adjFactor.shift(-1)\n",
    "    adjFactor = adjFactor.fillna(method='bfill').fillna(1)\n",
    "    adjFactor = adjFactor[~adjFactor.index.duplicated()]\n",
    "    return adjFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAdjOHLC(symbol):\n",
    "    print(\"Creating Adj OHLC for \" + symbol)\n",
    "    parser = lambda date: pd.datetime.strptime(date, '%Y-%m-%d')\n",
    "    if(os.path.exists(\"data/\" + 'NSE:' + symbol + \"_unadj\" + \".csv\") == True):\n",
    "        df = pd.read_csv(\"data/\" + 'NSE:' + symbol + \"_unadj\" + \".csv\", parse_dates=True, date_parser=parser, header=0)\n",
    "        df.Date = pd.to_datetime(df.Date, format = '%Y-%m-%d')\n",
    "        df = df.set_index(['Date'])\n",
    "        df = df[~df.index.duplicated()]\n",
    "        adjFactor = adjustmentFactor(symbol)[df.index.min():df.index.max()]\n",
    "        df['AdjClose'] = (df['Close'] / adjFactor['factor']).dropna()\n",
    "        df['AdjFactor'] = adjFactor['factor']\n",
    "        persistDF(df, symbol, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9668dbcc426a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "page = requests.get(index_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
